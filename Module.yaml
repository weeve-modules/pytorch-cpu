displayName: 'PyTorch CPU'
moduleName: 'pytorch-cpu'
description: 'Use your PyTorch model with CPU device settings.'
versionName: 'v1.0.0'
isPublic: true
categories:
  - 'Data Science'
type: 'Processing'
image:
  name: 'weevenetwork/pytorch-cpu'
  tag: 'v1.0.0'
  homepage: 'https://hub.docker.com/r/weevenetwork/pytorch-cpu'
repository: 'https://github.com/weeve-modules/pytorch-cpu'
envs:
  - name: Model Filename
    key: MODEL_FILENAME
    description: Filename of the model to load.
    value: 'my_model.pt'
    type: 'text'
    options: []
    dependencies: []
  - name: Model Download URL
    key: MODEL_DOWNLOAD_URL
    description: If model is stored online, then provide a download URL to parse the model. Leave empty field to search for the model in the local filesystem.
    value: ''
    type: 'text'
    options: []
    dependencies: []
  - name: Model Filepath
    key: MODEL_FILEPATH
    description: If model is stored in the local filesystem (above field for URL was left empty), then provide a path to the folder containing the model.
    value: '/Users/Desktop/ml-model'
    type: 'text'
    options: []
    dependencies: []
  - name: Ordered Labels
    key: ORDERED_LABELS
    description: Input data labels in the order of feeding into the model. Later a PyTorch tensor will be created to feed that data into the model in the given order.
    value: 'temperature, volume, pressure'
    type: 'text'
    options: []
    dependencies: []
  - name: Output Label
    key: OUTPUT_LABEL
    description: The output label at which data is dispatched.
    value: 'prediction'
    type: 'text'
    options: []
    dependencies: []
ports: []
envPorts: []
mounts:
  - container: '/model'
    host: 'MODEL_FILEPATH'
envMounts:
  - MODEL_FILEPATH
devices: []
envDevices: []
tags:
  - 'Python'
  - 'Processing'
  - 'Machine Learning'
  - 'Deep Learning'
  - 'PyTorch'
  - 'CPU'
icon: 'https://icons-020-demo.s3.eu-central-1.amazonaws.com/mi_pytorch-cpu_processing.png'
